{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from keras.layers import Conv2D, Conv2DTranspose, MaxPool2D, UpSampling2D, BatchNormalization, Lambda, Input, Concatenate, Dropout\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from keras.models import Sequential, Model\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Map data to floats in [0, 1]\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "# Add Gaussian noise to data\n",
    "noise_factor = 0.1\n",
    "x_train_noise = x_train + noise_factor * np.random.normal(size=x_train.shape)\n",
    "x_test_noise = x_test + noise_factor * np.random.normal(size=x_test.shape)\n",
    "\n",
    "# Clamp noisy data to [0, 1]\n",
    "x_train_noise = np.clip(x_train_noise, 0.0, 1.0)\n",
    "x_test_noise = np.clip(x_test_noise, 0.0, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 16, 16, 64)   3136        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 16, 16, 64)   256         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 8, 8, 64)     65600       batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 8, 8, 64)     256         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 4, 4, 128)    131200      batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 4, 4, 128)    512         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 2, 2, 128)    262272      batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 2, 2, 128)    512         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 1, 1, 256)    524544      batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 1, 1, 256)    1024        conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_6 (Conv2DTrans (None, 2, 2, 128)    524416      batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 2, 2, 128)    0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 2, 2, 256)    0           conv2d_transpose_6[0][0]         \n",
      "                                                                 lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 2, 2, 256)    1024        concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_7 (Conv2DTrans (None, 4, 4, 128)    524416      batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 4, 4, 128)    0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 4, 4, 256)    0           conv2d_transpose_7[0][0]         \n",
      "                                                                 lambda_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 4, 4, 256)    1024        concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_8 (Conv2DTrans (None, 8, 8, 64)     262208      batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 8, 8, 64)     0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 8, 8, 128)    0           conv2d_transpose_8[0][0]         \n",
      "                                                                 lambda_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 8, 8, 128)    512         concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_9 (Conv2DTrans (None, 16, 16, 64)   131136      batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 16, 16, 64)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 16, 16, 128)  0           conv2d_transpose_9[0][0]         \n",
      "                                                                 lambda_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 16, 16, 128)  512         concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 16, 16, 128)  0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_10 (Conv2DTran (None, 32, 32, 3)    6147        dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 2,440,707\n",
      "Trainable params: 2,437,891\n",
      "Non-trainable params: 2,816\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define amount of information gating for the Direct Symmetric Connections (DSCs) in each of the deconvolutional layers.\n",
    "# 1.0 = no residual (only deconv output)\n",
    "# 0.0 = only residual (no deconv output)\n",
    "gating_factor = 1.0\n",
    "\n",
    "# Input\n",
    "inputs = Input(shape=(x_train.shape[1:]))\n",
    "\n",
    "# Encoder\n",
    "conv_1 = Conv2D(64, 4, strides=(2, 2), activation='relu', padding='same')(inputs)\n",
    "conv_1 = BatchNormalization()(conv_1)\n",
    "\n",
    "conv_2 = Conv2D(64, 4, strides=(2, 2), activation='relu', padding='same')(conv_1)\n",
    "conv_2 = BatchNormalization()(conv_2)\n",
    "\n",
    "conv_3 = Conv2D(128, 4, strides=(2, 2), activation='relu', padding='same')(conv_2)\n",
    "conv_3 = BatchNormalization()(conv_3)\n",
    "\n",
    "conv_4 = Conv2D(128, 4, strides=(2, 2), activation='relu', padding='same')(conv_3)\n",
    "conv_4 = BatchNormalization()(conv_4)\n",
    "\n",
    "conv_5 = Conv2D(256, 4, strides=(2, 2), activation='relu', padding='same')(conv_4)\n",
    "conv_5 = BatchNormalization()(conv_5)\n",
    "\n",
    "# Decoder\n",
    "deconv_1 = Conv2DTranspose(128, 4, strides=(2, 2), activation='relu', padding='same')(conv_5)\n",
    "conv_4   = Lambda(lambda x: x * (gating_factor))(conv_4)\n",
    "deconv_1 = layers.Concatenate()([deconv_1, conv_4])\n",
    "deconv_1 = BatchNormalization()(deconv_1)\n",
    "\n",
    "deconv_2 = Conv2DTranspose(128, 4, strides=(2, 2), activation='relu', padding='same')(deconv_1)\n",
    "conv_3   = Lambda(lambda x: x * (gating_factor))(conv_3)\n",
    "deconv_2 = layers.Concatenate()([deconv_2, conv_3])\n",
    "deconv_2 = BatchNormalization()(deconv_2)\n",
    "\n",
    "deconv_3 = Conv2DTranspose(64, 4, strides=(2, 2), activation='relu', padding='same')(deconv_2)\n",
    "conv_2   = Lambda(lambda x: x * (gating_factor))(conv_2)\n",
    "deconv_3 = layers.Concatenate()([deconv_3, conv_2])\n",
    "deconv_3 = BatchNormalization()(deconv_3)\n",
    "\n",
    "deconv_4 = Conv2DTranspose(64, 4, strides=(2, 2), activation='relu', padding='same')(deconv_3)\n",
    "conv_1   = Lambda(lambda x: x * (gating_factor))(conv_1)\n",
    "deconv_4 = layers.Concatenate()([deconv_4, conv_1])\n",
    "deconv_4 = BatchNormalization()(deconv_4)\n",
    "deconv_4 = Dropout(0.25)(deconv_4)\n",
    "\n",
    "# Output\n",
    "deconv_5 = Conv2DTranspose(3, 4, strides=(2, 2), activation='sigmoid', padding='same')(deconv_4)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=deconv_5)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training parameters\n",
    "EPOCHS = 1 # more than 1 epoch causes this model to overfit on CIFAR-10\n",
    "BATCH_SIZE = 128\n",
    "VAL_SPLIT = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model with Adam optimizer\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizers.adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 17s 368us/step - loss: 0.5541 - val_loss: 0.5553\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "H = model.fit(x_train_noise, x_train, batch_size=BATCH_SIZE, epochs=EPOCHS, validation_split=VAL_SPLIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot losses (only useful for >1 epoch)\n",
    "plt.plot(H.history['loss'], color='blue', label='train loss')\n",
    "plt.plot(H.history['val_loss'], color='red', label='val loss')\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define result display constants\n",
    "DIMS = (256, 256)\n",
    "INTERP = cv2.INTER_CUBIC\n",
    "\n",
    "while True:\n",
    "    # Pick a random index into test set\n",
    "    i = np.random.choice(np.arange(x_test.shape[0]), size=(1,), replace=False)[0]\n",
    "\n",
    "    # Retrieve original image, noisy image, and label using index\n",
    "    orig_image = x_test[i]\n",
    "    noise_image = x_test_noise[i]\n",
    "    true_label = y_test[i]\n",
    "    \n",
    "    # Attempt to reconstruct original image from noisy image using model\n",
    "    recon_image = model.predict(np.expand_dims(noise_image, axis=0))\n",
    "    recon_image = np.reshape(recon_image, orig_image.shape)\n",
    "    \n",
    "    # Resize images for easy viewing\n",
    "    orig_image = cv2.resize(orig_image, DIMS, interpolation=INTERP)\n",
    "    noise_image = cv2.resize(noise_image, DIMS, interpolation=INTERP)\n",
    "    recon_image = cv2.resize(recon_image, DIMS, interpolation=INTERP)\n",
    "    \n",
    "    # Join original, noisy, and reconstructed images\n",
    "    combo_image = np.uint8(np.clip(np.hstack([orig_image, noise_image, recon_image]) * 255, 0, 255))\n",
    "    combo_image = cv2.cvtColor(combo_image, cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "    # Display joined images until a key is pressed, exiting on \"q\"\n",
    "    cv2.imshow(str(true_label), combo_image)\n",
    "    if cv2.waitKey(0) == ord('q'):\n",
    "        break\n",
    "    else:\n",
    "        cv2.destroyAllWindows()\n",
    "    \n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
